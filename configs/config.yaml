model:
  model_name_or_path: "EleutherAI/gpt-neo-125m"
  cot_length: 6
  max_length: 256
  use_lora: true
  lora:
    r: 128
    lora_alpha: 32
    target_modules: ["q_proj", "k_proj", "v_proj", "out_proj", "fc_in", "fc_out"]
    lora_dropout: 0.1
    bias: "none"